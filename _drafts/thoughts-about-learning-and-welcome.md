---
layout: post
title:  "Some Thoughts about Learning (and Welcome!)"
---

Welcome to my blog! I will be posting my personal thoughts and ideas about
Data Science, AI, Tech etc. But that's not all I'm here to talk about.

Having worked with Data Science, Machine Learning and programming for years,
I have to come to realize that these things are hard. Learning new algorithms
and programming languages are hard. But it doesn't have to be. The trick is to
divide difficult concepts into bite-sized chunks and learn them one by one.
Start with the basics and build from there. The same thing applies to
programming any software. You have to start small, build the foundations and
advance one thing at a time.

I'm using this blog as an example. I was thinking of starting with a massive
Data Science post with lots of interesting pictures, formulas, algorithms etc.
But I realized it's better to start small. Otherwise I'll never even get
started. After this first post everything will become easier.

Another more concrete example is how I learned how neural networks work, to the
point where I can implement them from scratch if needed. The learning process
went something like this:

- Learn about neurons, the most basic components (and their activation functions)
- How the neurons are connected in a simple feed-forward network
- How the weights are optimized during learning by using backpropagation during
  learning phase, based on the classification error
- How the network classifies new testing data with these learned weights and
  connections

Once you got the basics down everything else is just an add-on. Gradually it
becomes easier to understand things like:

- Different activation functions
- Deep Learning
- Recurrent Neural networks
- Autoencoders ...

They are all connected. I will be posting in more detail about neural networks
in the near future. Some years ago I thought they were a thing of the past,
but I feel Deep Learning has made them more relevant again. What hasn't changed,
however, is the fact that the basics are still the same.
