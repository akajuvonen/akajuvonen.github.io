---
layout: post
title:  "TensorFlow 1.5: What's New and Building from Source"
---

So, TensorFlow 1.5 [was released][tf15] a few days ago. I thought I'd give it
a go as soon as possible, since it has some interesting new features, and I
like new things in general. Of course there were some hiccups, but everything
is working now.

# What's new in 1.5 (for me)

The thing that interests me the most is [eager execution][eager], which means
operations are executed immediately and not lazily. As a programmer, I like
this because it resembles other Python scientific libraries. I haven't had
time to consider all the pros and cons, however.

In addition, TensorFlow now supports CUDA 9 and cuDNN 7. I found installing
CUDA 9 to be a bit easier on my machine, since I needed to run some extra
steps to get CUDA 8 working. In terms of performance, I haven't seen a
significant difference in my tests. Also, note to self: even though CUDA 9
is supported, it doesn't mean CUDA 9.1 works (9.1 is the latest version).
It seems some people got confused by this.

Of course there are many other improvements, but I'm not going to go into
details about those. They can be found on the official page.

# What I did to get it working

I run TensorFlow on multiple devices. One of my computers is an old desktop
with now ancient GeForce GTX 660. It still supports CUDA and seems to be much
faster than using CPU. Previously I have installed TF from the official pip
packages. They are precompiled so the installation is much faster.

Unfortunately my old GPU only has CUDA capability 3.0. When running a test
I got a warning along the lines of:

```
The minimum required Cuda capability is 3.5
```

Now, I know that TF works with 3.0, but I suppose the pip package was built
without support for anything under 3.5. Makes sense, really, since I would
assume most people have a bit more modern GPUs these days.

I guess we just have to build from source, then. Not a big deal, since I do
that all the time with other programs.

Mostly everything went smoothly by just following the official documentation.
I needed to limit the resources that Bazel uses for compilation to avoid
computer hanging. It can be done with the flag `--local_resources`.

There was one more problem, and unfortunately this was not mentioned in the
documentation. Bazel seemed to have problems finding cuDNN for some reason.
After some digging, I found that this was probably due to a bug in the build
which causes the build process to ignore `LD_LIBRARY_PATH` environmental
variable. Thankfully, I got it working by adding the following to the
`bazel build` command:

```
--action_env="LD_LIBRARY_PATH=${LD_LIBRARY_PATH}"
```

# Conclusion

Now I have the latest TensorFlow version working, compiled from source and
using the GPU correctly. In my small test it was already at least 5 times faster
than using the CPU. I didn't add any GPU-specific optimizations, either.

I suspect that most of the time for me it doesn't matter much if I'm using
TF 1.5 or 1.4, but it's still exciting to test new features and other
improvements. Also, from now the build process should be a bit faster since I
don't have to start everything from scratch.

[tf15]: https://developers.googleblog.com/2018/01/announcing-tensorflow-15.html
[eager]: https://developers.googleblog.com/2017/10/eager-execution-imperative-define-by.html
